{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86babd49-4a03-4ba8-b09e-fc74400b1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4efb3463-9eac-49d8-9f7a-97835577952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"microsoft/DialoGPT-medium\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f147844-41df-433b-ba98-eb61338aebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_pdf(pdf_text):\n",
    "    conversation_history = \"\"\n",
    "    context_chunk_size = 500  # Define the size of each context chunk\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Append user input to conversation history\n",
    "        conversation_history += f\"Human: {user_input}\\n\"\n",
    "\n",
    "        # Add a relevant chunk of PDF text to the conversation history\n",
    "        if len(pdf_text) > context_chunk_size:\n",
    "            pdf_chunk = pdf_text[:context_chunk_size]\n",
    "            pdf_text = pdf_text[context_chunk_size:]  # Remove the used chunk from the text\n",
    "        else:\n",
    "            pdf_chunk = pdf_text\n",
    "\n",
    "        conversation_history += f\"PDF: {pdf_chunk}\\n\"\n",
    "\n",
    "        # Print conversation history for debugging\n",
    "        print(\"Conversation History:\\n\", conversation_history)\n",
    "\n",
    "        # Encode the input\n",
    "        inputs = tokenizer.encode(conversation_history + \"Assistant:\", return_tensors=\"pt\")\n",
    "\n",
    "        # Generate a response\n",
    "        attention_mask = (inputs != tokenizer.pad_token_id) if tokenizer.pad_token_id is not None else None\n",
    "\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=1000,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        # Decode the response\n",
    "        response = tokenizer.decode(outputs[:, inputs.shape[-1]:][0], skip_special_tokens=True)\n",
    "        print(f\"Assistant: {response}\")\n",
    "\n",
    "        # Append response to conversation history\n",
    "        conversation_history += f\"Assistant: {response}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6f3b9-5872-4f18-9865-c6110eb85bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  summarize the file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation History:\n",
      " Human: summarize the file\n",
      "PDF:  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Reading  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "Answers:  \n",
      " \n",
      "B. \n",
      " \n",
      " \n",
      "  \n",
      "C. \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "Grammar  \n",
      " \n",
      "Skill 1:  \n",
      " \n",
      " \n",
      "-\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Answers:  \n",
      " \n",
      "D. \n",
      "  \n",
      "Skill 2  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Answers:  \n",
      "H. \n",
      " \n",
      " \n",
      "  \n",
      "Skill 3  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Answers:  \n",
      " \n",
      "1. It’s too expensive.  \n",
      "2. too much  \n",
      "not enough  \n",
      "not enough/too much  \n",
      "too many  \n",
      "too many  \n",
      "too much  \n",
      "not enough  \n",
      "3. Answers depend on students.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "References:  \n",
      " \n",
      "Philips, Anna & Philips, Terry (2017). Progressive skills in En\n",
      "\n",
      "Assistant: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is this file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation History:\n",
      " Human: summarize the file\n",
      "PDF:  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Reading  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "Answers:  \n",
      " \n",
      "B. \n",
      " \n",
      " \n",
      "  \n",
      "C. \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "Grammar  \n",
      " \n",
      "Skill 1:  \n",
      " \n",
      " \n",
      "-\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Answers:  \n",
      " \n",
      "D. \n",
      "  \n",
      "Skill 2  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Answers:  \n",
      "H. \n",
      " \n",
      " \n",
      "  \n",
      "Skill 3  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Answers:  \n",
      " \n",
      "1. It’s too expensive.  \n",
      "2. too much  \n",
      "not enough  \n",
      "not enough/too much  \n",
      "too many  \n",
      "too many  \n",
      "too much  \n",
      "not enough  \n",
      "3. Answers depend on students.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "References:  \n",
      " \n",
      "Philips, Anna & Philips, Terry (2017). Progressive skills in En\n",
      "Assistant: \n",
      "Human: what is this file\n",
      "PDF: glish \n",
      "(second) . The UK: Garnet.  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "\n",
      "Assistant: \n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in range(len(reader.pages)):\n",
    "            text += reader.pages[page].extract_text()\n",
    "    return text\n",
    "\n",
    "# Extract text from a PDF file\n",
    "pdf_path = \"C:/Users/Admin/Downloads/Class Three - ENG111 - English (2).pdf\"\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Start chat with the extracted PDF text\n",
    "chat_with_pdf(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836d9fd-ad6c-4179-aa74-755c06ab3413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
